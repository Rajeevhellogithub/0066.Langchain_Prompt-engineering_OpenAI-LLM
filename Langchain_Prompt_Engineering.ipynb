{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1e6dcf-91c2-4963-b7ac-588a759c7111",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Langchain Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2da1e28-1e71-4c27-a737-9bbc1914482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94361059-ace4-4039-adb6-ae8790b6ebdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb69ca-4c0f-44ef-b536-caaafbe7961a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Langchain Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3a0a0f-c6c1-4b8f-af8f-0955b11270df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baeb058-7bc0-40ac-83b4-cede57beb649",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Langchain Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5390f6e6-e744-46b4-9143-60337872079f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "output_parser.parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d025d244-b9a5-4d2f-aeeb-5bfcbc6f2736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to suggest file IT return. \\nIn an easy way, explain the basics of income tax.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "demo_template='''I want to suggest file IT return. \n",
    "In an easy way, explain the basics of {financial_concept}.'''\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=['financial_concept'],\n",
    "    template=demo_template\n",
    "    )\n",
    "\n",
    "prompt.format(financial_concept='income tax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b56adb-9cc2-41c9-be21-67229bcce953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(temperature=0.7)\n",
    "chain1 = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4fe1bc-411b-4c26-a3ed-8857c5dce578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Filing your income tax return is an important responsibility for every individual who earns an income. It is a way to declare your income and pay the applicable tax on it to the government.\n",
      "\n",
      "Here are the basic steps to file your income tax return:\n",
      "\n",
      "1. Determine your income: The first step is to calculate your total income for the financial year. This includes income from all sources such as salary, interest, rental income, capital gains, etc.\n",
      "\n",
      "2. Collect necessary documents: Collect all the necessary documents such as your Form 16, bank statements, investment proofs, etc. These documents will help you accurately calculate your taxable income.\n",
      "\n",
      "3. Choose the correct ITR form: The next step is to choose the correct income tax return (ITR) form based on your income sources and category. For example, if you are a salaried individual, you can file using ITR-1 form.\n",
      "\n",
      "4. Calculate your tax liability: Once you have your income and deductions in place, you can calculate your tax liability using the income tax slab rates applicable to your income category.\n",
      "\n",
      "5. File your return: You can file your income tax return online or offline. Online filing can be done through the Income Tax Department's e-filing website or through a third-party website.\n"
     ]
    }
   ],
   "source": [
    "response = chain1.invoke({\"financial_concept\": \"Income Tax\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5586064-2a18-4543-b2d7-d8feccd4b4d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Langchain Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf5ea31-0158-4d3e-917f-352b359e5fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'Generativa AI & LLM is the future for next 3 years', 'target_language': 'hindi', 'text': '\\n\\n\"जनरेटिव एआई और एलएलएम अगले 3 साल के लिए भविष्य है।\"'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "template = \"In an easy way translate the following sentence '{sentence}' into {target_language}\"\n",
    "\n",
    "language_prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\", \"target_language\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0.7)\n",
    "chain2 = LLMChain(llm=llm, prompt=language_prompt)\n",
    "\n",
    "response = chain2.invoke({\n",
    "    \"sentence\": \"Generativa AI & LLM is the future for next 3 years\",\n",
    "    \"target_language\": \"hindi\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ae04b-9ee4-4cde-bae9-a277d205eb6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Langchain Few Shot Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea36ddd5-2bde-4890-b2bc-d0807e1335f7",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/how_to/few_shot_examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f2c9d78-fbb8-43fc-965d-daf8d9fb3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9729c124-4b2b-4cd1-9d02-273f8ffba65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '2+2', 'output': '4'}, {'input': '2+3', 'output': '5'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "]\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88dba013-ede6-4271-8308-608294094da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 2+2\n",
      "AI: 4\n",
      "Human: 2+3\n",
      "AI: 5\n"
     ]
    }
   ],
   "source": [
    "# This is a prompt template used to format each individual example.\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d1971f-7a79-4b01-b3fd-b1a331e5a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# First, create the list of few shot examples.\n",
    "\n",
    "examples = [\n",
    "    {\"word\": \"success\", \"antonym\": \"failure\"},\n",
    "    {\"word\": \"placed\", \"antonym\": \"not placed\"},\n",
    "]\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "\n",
    "example_formatter_template = \"\"\"Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1802a00-f701-486a-af1e-8a5fc63df3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we create the `Few Shot Prompt Template` object.\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    examples = examples,\n",
    "    \n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    example_prompt = example_prompt,\n",
    "    \n",
    "    # The prefix is some text that goes before the examples in the prompt.\n",
    "    # Usually, this consists of intructions.\n",
    "    prefix = \"Give the antonym of every input\\n\",\n",
    "    \n",
    "    # The suffix is some text that goes after the examples in the prompt.\n",
    "    # Usually, this is where the user input will go\n",
    "    suffix = \"Word: {input}\\nAntonym: \",\n",
    "    \n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    input_variables = [\"input\"],\n",
    "    \n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "    example_separator = \"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "821b2dcd-d1f3-462a-a944-155efa836db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: success\n",
      "Antonym: failure\n",
      "\n",
      "Word: placed\n",
      "Antonym: not placed\n",
      "\n",
      "Word: big\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17a49ce8-fa53-4bf9-a5f0-b7224dbc978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'big', 'text': 'small'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "chain({'input':\"big\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowkernel",
   "language": "python",
   "name": "tensorflowkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
